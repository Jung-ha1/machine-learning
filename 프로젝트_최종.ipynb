{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "프로젝트 최종",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAsbB0Jpj0YR/5wGEu9sLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jung-ha1/machine-learning/blob/main/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ybBXdbvQHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ef96d-72c6-44fe-8dfd-60ce54cdb379"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "arr = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "y_data = [[1, 0, 2, 3, 3, 4]]\n",
        "\n",
        "num_classes = 5\n",
        "input_dim = 5 \n",
        "sequence_length = 6\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "x_one_hot = np.array([[[1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 1, 0, 0, 0],    # i 1\n",
        "                       [1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 0, 1, 0, 0],    # e 2\n",
        "                       [0, 0, 0, 1, 0],    # l 3\n",
        "                       [0, 0, 0, 1, 0]]],  # l 3\n",
        "                     dtype=np.float32)\n",
        "\n",
        " \n",
        "y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
        " \n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "\n",
        "cell = tf.keras.layers.LSTMCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "tf.model.add(tf.keras.layers.RNN(cell=cell, return_sequences=True))\n",
        "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tf.model.fit(x_one_hot, y_one_hot, epochs=50)\n",
        "tf.model.summary()\n",
        "\n",
        "predictions = tf.model.predict(x_one_hot)\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(prediction)\n",
        "    result_str = [arr[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6339 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5085 - accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4532 - accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4143 - accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3406 - accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2264 - accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1012 - accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9822 - accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8694 - accuracy: 0.8333\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7622 - accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6600 - accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5650 - accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4794 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3962 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3223 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2623 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1038 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn_3 (RNN)                  (None, 6, 5)              220       \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 6, 5)              30        \n",
            "=================================================================\n",
            "Total params: 250\n",
            "Trainable params: 250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[3.2575021e-04 9.9913460e-01 5.1499682e-04 7.1329815e-08 2.4575214e-05]\n",
            " [9.9693525e-01 1.0595497e-03 1.3192416e-04 1.3547996e-03 5.1846169e-04]\n",
            " [7.6014430e-06 6.4622529e-04 9.9871993e-01 5.9992290e-04 2.6296118e-05]\n",
            " [7.0182118e-04 3.3463863e-09 2.0958105e-04 9.9905044e-01 3.8146005e-05]\n",
            " [2.1787533e-05 1.2525715e-08 9.9146692e-04 9.9734288e-01 1.6438353e-03]\n",
            " [8.0705539e-04 3.2828993e-04 4.9883820e-04 2.0689927e-03 9.9629682e-01]]\n",
            "\tPrediction str:  ihello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUao_RKxEfU"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "arr = ['h', 'i', 'e', 'l', 'o']\n",
        "# 각각의 알파벳에 one-hot 인코딩을 하기 위해 배열을 만들어 준다.\n",
        "\n",
        "y_data = [[1, 0, 2, 3, 3, 4]]\n",
        "# y_data는 arr배열의 인덱스이며, y_data의 값을 부르게 되면 ihello라는 결과가 나옵니다.\n",
        "# 즉 x_data를 선언할 때 예시로 hileol을 학습시키면 ihello와 같이 나오도록 학습데이터를 선언해 준 것 입니다.\n",
        " \n",
        "\n",
        "num_classes = 5   # hielo를 분류한다.\n",
        "input_dim = 5 \n",
        "sequence_length = 6   # y_data의 길이\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "x_one_hot = np.array([[[1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 1, 0, 0, 0],    # i 1\n",
        "                       [1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 0, 1, 0, 0],    # e 2\n",
        "                       [0, 0, 0, 1, 0],    # l 3\n",
        "                       [0, 0, 0, 1, 0]]],  # l 3\n",
        "                     dtype=np.float32)\n",
        "# x_data를 학습시킬 때 x_data를 원핫 인코딩한 값으로 정해줍니다.\n",
        "\n",
        " \n",
        "y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
        "# y_data를 원핫 인코딩을 해줘야하는데, 즉 i= [0 0 0 0 0], h = [0 0 0 0 1]...과 같이 지정을 해줍니다.\n",
        "\n",
        "print(x_one_hot.shape)\n",
        "print(y_one_hot.shape)\n",
        "\n",
        " \n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "\n",
        "cell = tf.keras.layers.LSTMCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "# RNN 중 한개인 LSTM으로 input data를 6행 5열로 정렬해줍니다.\n",
        "\n",
        "tf.model.add(tf.keras.layers.RNN(cell=cell, return_sequences=True))\n",
        "# LSTM의 cell을 지정하고 Sequences = True란 명령어로 Time sequential한 데이터임을 선언해줍니다.\n",
        "\n",
        "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "# 수업에서 배웠던 ReLU 함수는 0이상의 값에서 y=x란 식이 나오며, 대부분 발산을 합니다.\n",
        "# 그런데 RNN은 과거의 데이터를 지속적으로 꺼내 사용하기 때문에 -1에서 1사이로 normalizing이 필요합니다. \n",
        "# 따라서 output layer의 값을 -1에서 1사이로 normalizing해줄 수 있는 softmax을 사용해 줍니다.\n",
        "\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tf.model.fit(x_one_hot, y_one_hot, epochs=50)\n",
        "tf.model.summary()\n",
        "\n",
        "predictions = tf.model.predict(x_one_hot)\n",
        "\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(prediction)\n",
        "    result_str = [arr[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}